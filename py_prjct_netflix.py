# -*- coding: utf-8 -*-
"""py_Prjct_netflix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ilmsm8YggKJlLPNuhgamBJ50Vdds5jvD
"""

### Data Analysis on the dataset of moviews Review  netflix_titles.csv

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd                    #importing various libraries and dataset
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
path ="/content/drive/MyDrive/Python_Tes/netflix_titles (1).csv"
dataset = pd.read_csv(path)

dataset = pd.read_csv(path)
dataset

print("Shape : ",dataset.shape)  # gives no. of rows and columns in the dataset

print(" Data types for each attributes ")
print(dataset.dtypes)

dataset.describe()    #describe gives us basic summary of our data (note works on only numeric columns)

dataset.groupby('type').size()  # getting the count of attribute in the type column

dataset.loc[:,["country"]]

Country = dataset.country.value_counts(sort=True)
Country    # getting the counts of country

dataset.iloc[10:25][['title','description']]

dataset[(dataset['release_year'] >= 2019) & (dataset['release_year'] <= 2020) & (dataset['rating']== 'TV-MA')]

grp=dataset.groupby(['director','type'])['type'].count()
director=grp.sort_values(ascending=False).head(5)
f = plt.figure()
f.set_figwidth(20)          #analyzing the top 5 director 
f.set_figheight(15)
ax=plt.axes()
director.plot.bar(color=['#fb6f92','#46ffb2','#6C8DFA','#fff146','#976ED7'],alpha=0.8)
plt.ylabel("Movies",size=12)
plt.xlabel("Directors",size=12)
plt.title("Top-5 Directors",size=15)
plt.show()

dataset['country'] = dataset['country'].fillna(dataset['country'].mode()[0])
dataset['cast'].replace(np.nan,'',inplace=True)
dataset['director'].replace(np.nan,'',inplace=True)                   # here data cleaning is done replacing the missing,dropping duplicates etc.
dataset.dropna(inplace=True)
dataset.drop_duplicates(inplace=True)
dataset['date_added'] = pd.to_datetime(dataset['date_added'])
dataset['month_added'] = dataset['date_added'].dt.month
dataset['month_name_added'] = dataset['date_added'].dt.month_name()
dataset['year_added'] = dataset['date_added'].dt.year

from PIL import Image
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
stopwords = set(STOPWORDS)

mask = np.array(Image.open("/content/drive/MyDrive/Python_Tes/netflix-logo-1-1200x675.png"))

def transform_zeros(val):
    if val == 0:
        return 255             # Wordcloud is basically a visualization technique to represent the
                               # frequency of words in a text where the size of the word represents its frequency.
    else:
        return val

maskable_image = np.ndarray((mask.shape[0],mask.shape[1]), np.int32)
for i in range(len(mask)):
    maskable_image[i] = list(map(transform_zeros, mask[i]))

wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = STOPWORDS, mask=maskable_image).generate(' '.join(dataset['title']))

def plot_cloud(wordcloud):
    # Set figure size
    plt.figure(figsize=(40, 30))
    # Display image
    plt.imshow(wordcloud) 
    # No axis details
    plt.axis("off");
plot_cloud(wordcloud)

z = dataset.groupby(['rating']).size().reset_index(name='counts')
pieChart = px.pie(z, values='counts', names='rating', 
                  title='Distribution of Content Ratings on Netflix',
                  color_discrete_sequence=px.colors.qualitative.Set2)
pieChart.show()

x = dataset.groupby(['type'])['type'].count()
y = len(dataset)
r=((x/y)).round(2)
mf_ratio = pd.DataFrame(r).T

fig, ax = plt.subplots(1,1,figsize=(6.5,2.5))
ax.barh(mf_ratio.index, mf_ratio['Movie'], 
        color='#e50914', alpha=0.9, label='Male')
ax.barh(mf_ratio.index, mf_ratio['TV Show'], left=mf_ratio['Movie'], 
        color='black', alpha=0.9, label='Female')
ax.set_xlim(0, 1)
ax.set_xticks([])
ax.set_yticks([])

for i in mf_ratio.index:
    ax.annotate(f"{int(mf_ratio['Movie'][i]*100)}%", 
                   xy=(mf_ratio['Movie'][i]/2, i),
                   va = 'center', ha='center',fontsize=40, fontweight='light', fontfamily='serif',
                   color='white')
    ax.annotate("Movie", 
                   xy=(mf_ratio['Movie'][i]/2, -0.25),
                   va = 'center', ha='center',fontsize=15, fontweight='light', fontfamily='serif',
                   color='white')
for i in mf_ratio.index:
    ax.annotate(f"{int(mf_ratio['TV Show'][i]*100)}%",
                xy=(mf_ratio['Movie'][i]+mf_ratio['TV Show'][i]/2,i),
                va = 'center', ha='center',fontsize=40, fontweight='light', fontfamily='serif',
                color='white')
    ax.annotate("TV Shows", 
                   xy=(mf_ratio['Movie'][i]+mf_ratio['TV Show'][i]/2, -0.25),
                   va = 'center', ha='center',fontsize=15, fontweight='light', fontfamily='serif',
                   color='white')
fig.text(0.125,1.0,'Movie & TV Show distribution',fontfamily='serif',fontsize=15,fontweight='bold')
fig.text(0.125,0.90,'We see vastly more movies than TV shows on Netflix.',fontfamily='serif',fontsize=12,fontweight='light')
for s in ['top','left','right','bottom']:
    ax.spines[s].set_visible(False)
ax.legend().set_visible(False)
plt.show()

filtered_genres = dataset.set_index('title').listed_in.str.split(', ', expand=True).stack().reset_index(level=1, drop=True);
plt.figure(figsize=(30,20))
g = sns.countplot(y = filtered_genres, order=filtered_genres.value_counts().index[:20])
plt.title('Top 20 Genres on Netflix',fontsize=26)
plt.xlabel('Titles',fontsize=26)
plt.ylabel('Genres',fontsize=26)
plt.show()

year_trend = dataset.release_year.value_counts(sort=True)
plt.plot(year_trend,'rs');    # seeing the trend and getting the result that there is drastical rise from 2005 to 2020

listed_in_most_common = dataset.listed_in.value_counts(sort=True).head(10)
listed_in_most_common

dataset['listed_in'].value_counts(sort=True).head(10).plot(kind='barh',)

s=input ("ENTER THE GENRE YOU WANT TO get details of : ")
if(s== "Thrillers"):
    Thrillers = dataset['listed_in'] == 'Thrillers'
    print(dataset[Thrillers].describe())
elif(s=="Comedies"):
    Comedies = dataset['listed_in'] == 'Comedies'
    print(dataset[Comedies].describe())
elif(s== "Dramas" ):
    Dramas = dataset['listed_in'] == 'Dramas'
    print(dataset[Dramas].describe())
else: 
    print ("Ente a valid name")

"""Geopy"""

l=[]
for countries in dataset['country']:
  l.append(countries)
l=list(set(l))
l                         # searching the countries column in dataset and and appending it to a list

from collections import Counter
print(Counter(l))

l1=[]
for element in l:
  a=element.split(',')
  l1.extend(a)          # splitting the counteries

l1=list(set(l1))
l1

from geopy.geocoders import Nominatim
from geopy.distance import geodesic as GD  
location=[]
la=[]
lo=[]
for i in range(2,len(l1)):
  geolocator = Nominatim(user_agent="my_request") 
  location1 = geolocator.geocode(l1[i])
  location.append(location1)
  la.append(location1.latitude)
  lo.append(location1.longitude)
# getting the longitude and latitude of all the countries in the list

import folium
import random  #plotting it in the map
world_Capital = folium.Map(location=[52.59493409735366, 89.89087938006628],zoom_start=2,tiles='CartoDB dark_matter')
color=['red','blue','pink','green','black','darkblue','violet','yellow']
for i in range(2,len(la)):
  folium.Marker(
        location=[la[i], lo[i]],tooltip=location[i],icon=folium.Icon(color=random.choice(color))).add_to(world_Capital)

world_Capital

"""**Regex**"""

b=input("Enter the cloumn you want to search in ")
a=input("Enter the initials of what you want to search ")
regex = a+'.*'
z=dataset[dataset[b].str.match(regex)]   # searching data with the help of regex
z

